# Conclusion



<!--<!--reIntro about the goal-->-->

<!--The main purpose of the this study was to evaluate the predictive performance of various machine learning models to real data on Airbnb listings in the city of New York.-->

<!--<!--List methods and their results, which is the best-->-->

<!--The methods used in this study consisted of simple and multiple linear regression, ridge regression, lasso regression, and XGBoost. The models were compared and assessed using mean square error and coefficient of determination criteria.--> 

<!--This study has shown that gradient boosting with all features (XGBoost) perform the best among all models. Ridge regression-->
<!--has the second best performance. While the performance of Lasso is not as good as Ridge Regression and XGBoost, Lasso performs feature selection. As a result, we were able to find a sparse models, which includes osanly relevant variables.  Linear Regression performs the worst proved that  the abundance of features leads to high variance and weak performance (overfitting).-->

<!--<!--Findings about location features-->-->

<!--The second aim of this study was to identify which characteristics of an Airbnb listing were most important in predicting the price. We found that the most important feature is whether the type of listing, e.g. entire home followed by the number of bath rooms. In addition, location features play an important role in predicting price.-->

<!--These findings are useful to develop a reliable price prediction model  to aid the Airbnb hosts to maximize their earnings.--> 

<!--<!--Future works-->





This study's primary purpose was to evaluate the predictive performance of various machine learning models to real data on Airbnb listings in the city of New York.
The methods used in this study consisted of simple and multiple linear regression, ridge regression, lasso regression, and XGBoost. The models were compared and assessed using mean square error and coefficient of determination criteria. 

This study has shown that gradient boosting with all features (XGBoost) performs the best among all models. Ridge regression has the second-best performance. 
While Lasso's performance is not as good as Ridge Regression and XGBoost, Lasso performs feature selection. With Lasso, we were able to find a sparse model, which includes only relevant variables. 
Linear Regression performs the worst proved that the abundance of features leads to high variance and weak performance (overfitting).

The second aim of this study was to identify which characteristics of an Airbnb listing were most important in predicting the price. We found that the most critical feature is whether the type of listing is an entire home or not. The second most important feature is the number of bathrooms. Also, location features play an essential role in predicting price. These findings help develop a reliable price prediction model to aid the Airbnb hosts in maximizing their earnings. 



In future work, we would like to:

1. Experiment with the data with Neural Network.
2. Find a way to include listing's photo quality as a predictor.
3. Incorporate customer reviews feature through sentiment analysis.